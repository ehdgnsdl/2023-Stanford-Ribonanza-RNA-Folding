{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e40d26-6f88-4537-8db7-ce403a1d115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0480314c-b016-4a5d-917d-e89e3abc7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from argparse import Namespace\n",
    "import gc\n",
    "import lightning.pytorch as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "sys.path.append(\"main\")\n",
    "from bottle import RNA_Lightning\n",
    "from data import RNA_DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e362ba8-0522-4c4f-a5df-553a66d08daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies a list of model checkpoint paths.\n",
    "ckpt_paths  = [\n",
    "    \"exp/e34/version_59/epoch=15-step=8272.ckpt\",\n",
    "    \"exp/e34/version_60/epoch=8-step=4662.ckpt\",\n",
    "    \"exp/e34/version_61/epoch=10-step=5687.ckpt\",\n",
    "    \"exp/e34/version_62/epoch=16-step=8789.ckpt\",\n",
    "    \"exp/e34/version_63/epoch=8-step=4662.ckpt\",\n",
    "\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60ed948-3b33-4dee-9233-c98937b7097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_idx: 59...\n",
      "Result_5Fold_cv01273/e35v_pseudo_59_epoch=15.parquet\n",
      "250\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donghun/anaconda3/envs/roger/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0313a631384b91a7503639507d7af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                       | 0/? [00:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_idx: 60...\n",
      "Result_5Fold_cv01273/e35v_pseudo_60_epoch=8.parquet\n",
      "250\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donghun/anaconda3/envs/roger/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6867db9b8e4458a20b3e0730c89154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                       | 0/? [00:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_idx: 61...\n",
      "Result_5Fold_cv01273/e35v_pseudo_61_epoch=10.parquet\n",
      "250\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donghun/anaconda3/envs/roger/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703a8d2f24c34f22867c62e599e7500f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                       | 0/? [00:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_idx: 62...\n",
      "Result_5Fold_cv01273/e35v_pseudo_62_epoch=16.parquet\n",
      "250\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donghun/anaconda3/envs/roger/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e79a779e48748efabc296789cdd912e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                       | 0/? [00:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_idx: 63...\n",
      "Result_5Fold_cv01273/e35v_pseudo_63_epoch=8.parquet\n",
      "250\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donghun/anaconda3/envs/roger/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e223c204fd45f49d6a54d104c1779b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                       | 0/? [00:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "for ckpt_path in ckpt_paths:\n",
    "    epoch_idx = ckpt_path.split('/')[3].split('-step')[0]\n",
    "    version_idx = ckpt_path.split('/')[2].split('_')[-1]\n",
    "    print(f'version_idx: {version_idx}...')\n",
    "    \n",
    "    output_name = f\"Result_5Fold_cv01273/e35v_pseudo_{version_idx}_{epoch_idx}.parquet\"\n",
    "    print(output_name)\n",
    "    df_infer = \"data/test_sequences_processed_ALL.parquet\"\n",
    "    n_workers = 8\n",
    "    \n",
    "    # GPU 메모리 초기화\n",
    "    torch.cuda.empty_cache()\n",
    "    # 가비지 컬렉터 호출\n",
    "    gc.collect()\n",
    "\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    \n",
    "    hp = Namespace(**ckpt[\"hyper_parameters\"])\n",
    "    print(hp.batch_size)\n",
    "    # hp.batch_size *= 4\n",
    "    hp.batch_size = 500 \n",
    "    print(hp.batch_size)\n",
    "    dm = RNA_DM(hp, n_workers, pd.read_parquet(df_infer))\n",
    "    model = RNA_Lightning.load_from_checkpoint(ckpt_path, hp=hp, strict=False)\n",
    "    model.eval()\n",
    "    preds = pl.Trainer(\n",
    "        precision=\"16-mixed\",\n",
    "        accelerator=\"gpu\",\n",
    "        benchmark=True,\n",
    "        enable_model_summary=False,\n",
    "        logger=False,\n",
    "    ).predict(model, datamodule=dm)\n",
    "\n",
    "    preds = torch.concat(preds)\n",
    "    pred_cols = [\"reactivity_DMS_MaP\", \"reactivity_2A3_MaP\"]\n",
    "    preds = pd.DataFrame(preds.float(), columns=pred_cols)\n",
    "    preds.insert(0, \"id\", preds.index)\n",
    "\n",
    "    preds.to_parquet(output_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f374b8-b624-416c-9141-b30409f93f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roger",
   "language": "python",
   "name": "roger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
